# Reinforcement Learning Algorithms' Empirical Analysis (using descriptive statistics)

Research on the comparative analysis of reinforcement learning algorithms including SARSA, Q-learning and Proximal Policy Optimization in addition to benchamrks which includes dynamic programming, value iteration and nested-benders' decoposition using a disaser response resource allocation environment model.

Please note that we are continuing to work on this repository to extend and improve the used DRL methodology in terms of sample efficiency. As such, the code in the current branch may not reflect the code submitted with the original paper. We will keep the paper branch frozen with the code from the original paper, and only update it as needed to fix bugs.


## Authors

- [@moizca](https://www.github.com/moizca)

- under the supervision of **Dr. Muhammad Salman Habib**
## Paper


## Colleborations

Colleborations are always welcome for any valid extension of this work!

I am specifically interested in deep learning based multi-stage optimization algorithms and their applications for solving complex transporation problems.
## üöÄ About Me
I am an engineer and a researcher in transportation engineering and logistics...


## Installation

All the relavent packages will be automatically installed upon the execution of a particular notebook.

Before installation of all the relavent packages, all the nodebooks will first install either Python 3.7 or Julia as they are the requirement to run proximal policy optimization and nested benders' decomposition implementations respectively. 
    
## Support

For support, email moizahmadnust@gmail.com


## Lessons Learned

Upon implementation of reinforcement learning (approximate dynamic programming) algorithms, I have learned the workings of multi-stage optimization methodologies.

Also, in the process, I have red vast amounts of pertinent liturature which helped me gain valuable insights and guidance for future research.


## Application

The implemeted algorithms alongwith our algorithmic innovations are tested on a realistic case study of an earthquake response operation in hard to reach city of Chitral in Northwestern Himalayas.

## How to Run?

Run on Google Colaboratory or any other similar environment

Just upload a notebook on Google Colab after setting the appropriate runtime depending upon the respective notebook requirements (either "CPU" or "GPU").

For detailed experimental setup and parameter settings please refer to the experimental setup subsection under the methodology heading.

For Proximal policy optimization (PPO) there are two notebooks, first instanlls packages using pip while the other installs packages by first creating a conda virtual environment and then all the installations are done within that environment.

Different problem instances can be run by adjusting parameters given under the first level markdown text cell named "Model Parameters".

### Logs

The log includes an excel file which includes data for the convergece curve (for a single run on a particular problem instance) as well as the values of stage-wise objective, state variables and decsion variables resulted from the trained policy.

In addition total amount of training simulation data will also be given.
## Feedback

If you have any constructive feedback, please reach out to us at moizahmadnust@gmail.com


## Miscellaneous
üë©‚Äçüíª I'm currently working on utilizing as well as designing different deep learning based multi-stage optimization approaches for tackling complex urban logistics and transportation problems

üß† I'm currently learning deep learning based multi-stage optimization approaches

üëØ‚Äç‚ôÄÔ∏è I'm looking to collaborate on my research at the intersection of urban logistics and operations research.

üí¨ Ask me about transportation engineering and operations research

üì´ How to reach me: moizahmadnust@gmail.com

üòÑ Pronouns: his/him

‚ö°Ô∏è Fun fact: I am curious.


### üõ† Skills
Python, Julia, Reinforcement learning, dynamic programming, transportation engineering, logistics, operations management

